---
title: "Evaluating Alzheimer’s Models on Imbalanced"
description: "In early AD and mild cognitive impairment (MCI), diffusion parameters reveal consistent ..."
author: "Thanusi Logathas"
category: "Alzheimers"
date: "06-25-2025"
---

**What are the Best Validation Strategies for Evaluating Alzheimer’s Models on Imbalanced and Longitudinal Datasets?**  
Written By: Thanusi Logathas

_Alzheimer's disease (AD) is a neurodegenerative condition categorized by memory impairment and cognitive decline. AD is the most common form of dementia, accounting for 60-80% of cases worldwide, typically affecting individuals over the age of 65\. Although experts do not yet fully know or understand the root cause of AD, it is believed to be a result of a combination of factors, including genetics, age, lifestyle, and environment._  
_As the importance of machine learning (ML) in supporting early AD diagnosis and prognosis increases, there remains a critical need for developing reliable and generalizable diagnostic models. However, the datasets used to train these particular models present two major challenges: class imbalance and longitudinal structure. In many cases, datasets are heavily skewed, containing far more healthy individuals than those diagnosed with AD. Such datasets can cause predictive models to perform very poorly in actually identifying AD-positive cases. Secondly, Alzheimer's data is collected over time, given the nature of the disease's progression, creating inherent temporal dependencies that cannot be overlooked during model validation._  
_This paper investigates how different validation strategies, such as cross-validation and bootstrapping, perform in the context of these challenges. The research focuses on evaluating which methods are most effective at minimizing bias, preventing information leakage, and yielding accurate performance assessments when applied to imbalanced and longitudinal Alzheimer's datasets._

**Introduction**

An accurate validation of the prediction algorithms in AD requires understanding the methods and the nature of the data. Cross-validation (CV), for example, k-fold CV, is the most widely recognized method, largely because it is easy to implement and computationally efficient (Rani et al., 2024). The data is split into k parts, using one for testing and the others for training, until each fold has been used for both training and testing (Rani et al., 2024). If the data is imbalanced, this method usually favours the majority class, normally healthy control subjects, and thus yields improper optimistic results. Nonetheless, stratified k-fold CV somewhat addresses this by keeping the class proportions in each fold, but the temporal aspect of longitudinal data remains unconsidered (Rani et al., 2024).  
Another validation technique called bootstrapping resamples the dataset with replacement to compute the model performance under different training sets. Despite being a valid option for smaller datasets, it randomizes the data and destroys temporal order in longitudinal studies. To address the temporal aspect of the data, time-aware methodologies have been proposed. One such procedure is Leave-One-Subject-Out Cross-Validation (LOSO-CV), which keeps data for one individual in the test set and learns from the rest, thereby avoiding temporal leakage and simulating real-world clinical applications (Lin et al., 2023).  
Moreover, research by Samper-González et al. (2018) has shown that LOSO-CV produces more realistic results than standard CV in the domain of Alzheimer's data. Similarly, in 2024, the study by Rani et al. (2024) showed that stratified sampling and cost-sensitive learning enhanced the performance tremendously in classification tasks using Random Forest classifiers, particularly under class-imbalanced situations. It can be understood from here that simply one single method is not sufficient; instead, temporal-aware validation combined with class balance techniques is likely the most effective path forward.  
In the study by Ma et al. (2024), 3D volumetric brain MRI datasets of healthy and Alzheimer's patients were collected. The training set contains a total of 18 samples: 9 of normal brains and 9 of brains affected by Alzheimer's. The dataset and images are used to scrutinize the structure of the brain and compare images of normal individuals with those who are diagnosed with Alzheimer's.

**Methodology**

When predicting Alzheimer's disease using ML models, researchers have applied several validation strategies to address the challenges of imbalanced class distribution and longitudinal data structures. This methodological literature review focuses on synthesizing and comparing validation methods based on their application in prior peer-reviewed studies, compared to providing original experiments. The central focus is the evaluation of these methods' strengths, weaknesses, and applications to improve the reliability and generalizability of the models.

**_Data Collection Methods_**

Many studies have gathered information from longitudinal sources such as the Alzheimer's Disease Neuroimaging Initiative (ADNI) and the Open Access Series of Imaging Studies (OASIS). These databases contain repeated clinical and neuroimaging measurements at different time intervals, making them apt for studying Alzheimer’s progression. However, one drawback in validating methods involves the longitudinal nature of the data since partitions chosen incorrectly could lead to data leakage and overly optimistic performance reporting (Varoquaux et al., 2016). Samper-González et al. (2018) discuss the importance of temporally-aware validation, proposing a framework centred around leave-one-subject-out cross-validation (LOSO-CV). This prevents the same-subject data from appearing in both the training and test sets. Furthermore, a structured clinical dataset including features such as demographic variables, neuropsychological test scores, and diagnostic labels, contained class-imbalanced samples that reflected common real-world distributions (Rani et al., 2024).

**_Data Analysis Techniques_**

Ma et al. (2024) developed a deep learning architecture with multi-scale attention for the MRI-based AD classification. It consists of the CNN backbone with attention layers to emphasize discriminative brain regions. Also, they adopted a subject-level data split in which all time points from the same subject were used either for training or for the test set, but never both. Additionally, they further applied batch normalization and dropout to mitigate overfitting, where the techniques were evaluated using classification metrics like accuracy and AUC, and also monitored the training curve along with confidence intervals to check for training stability.  
Rani et al. (2024) used a Random Forest-based classifier, where the training data posed a significant class imbalance. This challenge was addressed by using stratified k-fold cross-validation, Synthetic Minority Oversampling Technique (SMOTE), and cost-sensitive learning. However, SMOTE was applied only to the training data to prevent leakage (Rani et al., 2024). Cost-sensitive learning altered the misclassification cost for the minority (AD-positive) class to increase the sensitivity of the model. Therefore, an improved and enhanced metric regarding sensitivity and F1-score was reported.

**Findings**

The review of existing literature reveals that the validation strategies most often devoted to scrutinizing Alzheimer's disease mechanisms greatly vary in their effectiveness. Although the standard k-fold cross-validation is commonly adopted in machine learning research, it can be problematic in this particular context of imbalanced and longitudinal datasets. This is because it can cause data leakage or repeated measures from the same individuals and result in overly optimistic performance estimates. To prevent this, stratified k-fold cross-validation has been used in studies, improving the reliability of performance metrics in situations where AD-positive cases are underrepresented. However, this procedure alone fails to address temporal leakage in longitudinal data.  
Among the evaluated strategies, leave-one-subject-out cross-validation (LOSO-CV) has consistently been deemed the most suitable for longitudinal datasets. By ensuring that the test set contains data from a non-training subject, it can, in turn, preserve temporal sequence integrity and avoid subject overlap. Other studies show that LOSO-CV produces more realistic and generalizable results in Alzheimer's classification tasks involving neuroimaging data. Research conducted by Lin et al. (2023) states that using LOSO-CV reduced overfitting and produced an accuracy of 82.5% compared to 74.3% with a k-fold CV. Additionally, bootstrapping is found to be useful in estimating variability in small datasets, though it must be applied carefully to maintain the time-based nature of the data. While bootstrapping is less commonly used for longitudinal Alzheimer's data, its value lies in providing confidence intervals around performance estimates, especially when paired with other strategies.  
The findings demonstrate that there is no single validation method that is sufficient for both imbalance and longitudinal data. But rather, incorporating both LOSO-CV and stratified resampling techniques will be the most effective. The combination of the two methods allows for the maintenance of the data structure while also improving the generalizability of ML models in the research of Alzheimer's.

**Conclusion**

This study analyzed the strengths and limitations of several validation strategies for predicting Alzheimer's disease using imbalanced and longitudinal data. As Alzheimer's is becoming increasingly common, improving methods of evaluating models and combining methods for increased reliability and accuracy is important.

––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––

**References**

Afzal, M. T., Lone, M. A., & Ahmad, J. (2019). Alzheimer’s disease detection using augmented 3D MRI data: Addressing class imbalance. _Neural Computing and Applications_, 31(12), 8277–8290. [https://doi.org/10.1007/s00521-018-3986-4](https://doi.org/10.1007/s00521-018-3986-4)  
Lin W, Tong T, Gao Q, Guo D. 2023\. Early Alzheimer’s disease detection using CNNs: The role \_\_\_\_\_ of longitudinal MRI data. _Brain Informatics_, 10(1): 1-10.  
Mayo Clinic. (2024, November 8). _Alzheimer’s disease_. Mayo Clinic; Mayo Foundation for  
Medical Education and Research (MFMER). [https://www.mayoclinic.org/diseases-conditions/alzheimers-disease/symptoms-causes/syc-20350447](https://www.mayoclinic.org/diseases-conditions/alzheimers-disease/symptoms-causes/syc-20350447)  
Rani, S., Sharma, A., & Dey, N. (2024). A machine learning model for Alzheimer's disease prediction. _IET Cyber-Physical Systems: Theory & Applications, 19_(2), 123–130. [https://doi.org/10.1049/cps2.12090](https://doi.org/10.1049/cps2.12090)  
Samper-González, J., Burgos, N., Bottani, S., Fontanella, S., Lu, P., Marcoux, A., & Colliot, O. (2018). Reproducible evaluation of classification methods in Alzheimer’s disease: Framework and application to MRI and PET data. _NeuroImage, 183_, 504–521. [https://doi.org/10.1016/j.neuroimage.2018.08.042](https://doi.org/10.1016/j.neuroimage.2018.08.042)  
Varoquaux G, Raamana PR, et al. 2016\. Assessing and tuning brain decoders: cross-validation,  
caveats, and guidelines. _NeuroImage_, 145:166–179.  
[https://doi.org/10.1016/j.neuroimage.2016.10.038](https://doi.org/10.1016/j.neuroimage.2016.10.038)
